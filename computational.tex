\setlength{\parindent}{2ex}
\newcommand{\Ab}{{\bf A}}
\newcommand{\N}{\mathcal{N}}
\begin{chapter}{Reconstruction on the Computer}\label{chapter:computational}

In the last chapter, we established the theory for defining the inverse problem in an infinite dimensional Hilbert space. 
The development led to defining the functional $\Phi:\HH_1 \times \HH_2 \to \R$
\begin{equation} \label{eq:regularizingFunctional}
  \Phi(p; b) = \lambda\|\G p - b\|_{\HH_2}^2 + \delta\langle p, \L p\rangle_{\HH_1},
\end{equation}
where $\G$ is the operator that takes a radial profile $p$ to a line of blurred image of an edge $b$, and $\L$ is the induced radial Laplacian. 
We also showed that $\L^n$ was trace class for all $n$ in $\HH_1$. %, which allowed for a well-defined posterior probability measure for $p$.
Hence, in the infinite dimensional Bayesian perspective, if $p\sim \mu_p$ where $\mu_p$ is a Gaussian measure with mean $0$ and precision $\delta \L$, then in the presence of independent noise precision $\lambda I$ (with corresponding measure $\mu^b$) the posterior is Gaussian with a Radon-Nykodym derivative with respect to $\mu_p$
%we modeled the likelihood as a white-noise process with covariance $\lambda \delta$, which with the assumption that $p$ is random variable distributed by a Gaussian measure, $\rho_0$, on $\HH_1$ with zero mean and the radial Laplacian as the precision operator $L$, radon $p$  
%That is, in the infinite dimensional Bayesian perspective, when $\lambda$ and $\delta$ were given this led to a conditional random variable for $p$ with Gaussian measure and a probability density
\begin{equation} \label{eq:posteriorInfinite}
  \frac{\mu^b}{\mu_p}(p) \propto \exp\left(-\Phi(p;b)\right),
\end{equation}
where $\Phi(p;b)$ is unique up to scaling by a factor dependent on $b$.
We called this the infinite dimensional posterior for $p$ given $b$.

Of course, to carry out numerical estimation, the data and the estimate for the PSF must be represented by a finite set of numbers on computer.
In the framework of \citep{stuart2010}, one would design an algorithm that samples the \emph{infinite} dimensional posterior. 
This approach was undertaken in \citep{agapiou2014analysis} for linear inverse problems with a Laplacian precision operator and a hierarchical Gamma prior for $\delta$ with a given estimate for $\lambda$. 
They analyzed the infinite dimensional Gibbs sampler, and showed that it had deficiencies in sampling $\delta$ that exacerbate as the discretization converges.
They then introduced two algorithms that alleviate this issue.
Although their analysis is not directly applicable to PSF reconstruction since our prior is the \emph{radial} Laplacian, we take cues from their work to design the algorithm for exploring the \emph{discrete} posterior density for PSF reconstruction.
Also, by discretizing at this stage, we will be able to develop an algorithm that allows for the noise precision $\lambda$ to be estimated.

The discrete representations will be point-based on equally spaced grids, and each operator defined in the \Cref{chapter:theoretical} will be estimated using either numerical quadrature or finite differencing.
Hence, to each operator we will define a matrix that defines their action on the point-wise estimates, and they will be derived in \Cref{sec:discretization}
We then develop the \emph{discrete} probability spaces associated with the matrix-operators defined in \Cref{sec:discretization}, which will serve as our discrete approximation of the infinite dimensional space defined in \Cref{chapter:theoretical}.
In this development, we will add ``uninformative'' prior assumptions for the parameters $\lambda$ and $\delta$, forming a hierarchical Bayesian model.
From there, the discrete posterior distribution can be expressed in terms of conditional distributions in such a way so that Markov Chain Monte Carlo sampling techniques (e.g. Gibbs sampling) can be applied to provide estimates and quantification of uncertainty.
In \Cref{sec:pcgibbs}, we will derive a standard Gibbs' sampling algorithm \cite{geman1984stochastic} and improve upon it using a technique called \emph{partial collapse}, which can motivated by several recent theoretical and practial analyses \citep{van2008partially,agapiou2014analysis,fox2015fast}.
We will also briefly review standard convergence diagnostics for comparing Markov Chain based sampling algorithms, which will show that our adapted algorithm is indeed an enhancement of standard Gibbs' sampling.

\section{Discrete representation of the inference problem} \label{sec:discretization}

Recall that the radial Laplacian $\L: \HH_1 \to \HH_1$ acted by
\begin{equation} \label{eq:infiniteRadialLaplacian}
  [\L p](r) = r^{-1}\frac{d}{dr}\left(r \,\frac{d}{dr}p(r)\right). 
\end{equation}
Recall also that the inner product for the regularization is also affected by the change of variables, i.e.
\begin{equation} \label{eq:infiteRadialInnerProduct}
  \langle p_1, \L^n p_2 \rangle_{\HH_1}
    = 2\pi\int_0^\infty p_1(r) [\L^n p_2](r) \, rdr. 
\end{equation}

%For numerical estimation, we discretize the forward integral operator in (\ref{fredholmEquation}) using midpoint quadrature, and, imposing the same resolution on the reconstructed radial profile as the data results in $\Ab$ being an $N \times (N-1)/2 = N\times M$ matrix.
The differential operator $R$ is discretized using centered differencing, i.e.~for $h = 1/M$ denote $r_{j\pm1/2} = h\cdot j \pm h/2$, $x_j = x(r_j)$ and
\begin{equation}
  [\bm R \bm x]_j \eqdef \frac{1}{h^2} \Big( r_{j+1/2}(x_{j+1} - x_j) - r_{j-1/2}(x_{j} - x_{j-1})\Big).
  \label{laplacian_discretization}
\end{equation}
or as a matrix stencil
\begin{equation}
  \frac{1}{h^2}
  \left[\begin{array}{ccc}
    -(r_{j-3/2} + r_{j-1/2}) & r_{j-1/2} & 0             \\
    r_{j-1/2} & -(r_{j-1/2} + r_{j+1/2}) & r_{j+1/2}     \\
    0 & r_{j+1/2} & -(r_{j+1/2} + r_{j+3/2}) \\
  \end{array}\right]
  \left[\begin{array}{c}
    x_{j-1} \\
    x_{j}   \\
    x_{j+1} \\
  \end{array}\right].
  \label{laplacian_discretization_stencil}
\end{equation}
The discretization of $\bm R$ has a zero right boundary condition since $\lim\limits_{r\to\infty}x(r) = 0$ (we assume the domain for the radial profile is sufficiently large so that $r_M$ is less than machine epsilon) and a reflective left boundary condition because of the assumption of radial symmetry.
We then take $\bm L = \bm r^{-1} \odot \bm R^2$, i.e., the coordinate wise multiplication of reciprocals of the grid points $r_j$ composed with $\bm R^2$.
Finally, the discretization of the transformed inverse problem is
\begin{equation}\label{eq:psfDiscInvProblem}
  \bm b = \Ab x + \bm \eps,
\end{equation}
with $\bm \eps \sim \N(\bm 0, \lambda^{-1} \bm I)$ and $\bm x \sim \N( \bm 0, \delta^{-1} \bm (\bm L^T\bm L)^{-1})$.
  \subsection{The discrete posterior distribution}
\section{Markov Chain Monte Carlo estimation} \label{sec:pcgibbs}
In this section we give an overview of Markov Chain Monte Carlo (MCMC) methods for analyzing a probability distribution known up to a scaling constant.
Statistical analysis is based on the ergodic theorem for Markov chains, which can be thought of as the analogous central limit theorem for Markov chains. 
These notions will be briefly overviewed in the next section, and complete treatments can be found in \citep{robert2013monte,liu2008monte}.
In the context of PSF reconstruction, samples will be taken from the posterior $p(\vect x,\delta,\lambda|\vect b)$.
Our development will lead to an algorithm based on Gibbs' sampling that uses a technique referred to as partial collapse.  
In partially collapsed Gibbs sampling, conditional densities are modified to remove dependence between components of the joint density.
Our use of partial collapse will be motivated by the marginal algorithm in \citep{agapiou2014analysis}, a similar infinite dimensional sampler.

In what follows, we will develop theory for a general $p$ component u
Note that the model PSF estimation has $p=3$ components, and the general development is not necessary for this problem.
We've developed this process in the general setting, with potential modifications to the hierarchical model in mind.
In \citep{howard2015Sensitivity}, they observed potential sensitivity to the uninformative hyper-prior parameters $\alpha_\delta,\beta_\delta,\alpha_\lambda$ and $\beta_\lambda$ in a similar hierarchical Bayesian estimation problem.
A possible extension would be to impose a conjugate prior distribution on these parameters, in which case $p=7$.

  \subsection{Markov Chains}
This subsection is devoted to developing the preliminary notions of Markov Chains and the prerequisite theory for using Markov chains for Monte Carlo estimation. 
We assume a probability (measure) space $(\Omega,\mathcal F,\mathbb P)$ where $\Omega$ is the set of outcomes, $\mathcal F$ a sigma-algebra of events from $\Omega$ and $\mathbb P$ a measure on $\mathcal F$ into $[0,1]$.
We will be concerned with sampling a $p$ component random variable $\vect X = (X_1\dots X_p):\Omega \to \R^N$ so that the measure (known as its \emph{law}) induced by $X$ on $\R^N$ by taking pre-images of Borel sets is absolutely continuous with respect to Lebesgue measure.
Hence, each law corresponding to $X_i$ has a density (its Radon-Nykodym derivative with respect to Lebesgue measure) $\pi_{\vect X}(\vect x) = \pi_{\vect X}(x_1\dots x_p)$, where $X_i$ take on values in $\R^{k_i}$ such that $\sum k_i = N$.
For a complete development of the measure-based probabilistic formulation of random variables see \citep{durrett2010probability,billingsley2008probability}.
When the density is clear from context, we will omit the subscript on $\pi(\vect x) \eqdef \pi_{\vect X}(\vect x)$.
Denote the vector with the $i$th component removed $\rem{x}{i} \eqdef (x_1\dots x_{i-1},x_{i+1}\dots x_p)$, then the \emph{marginal distribution} is
\begin{equation}
  \pi(\rem xi) \eqdef \int_{x_i} \pi(x_1\dots x_p)dx_i,
\end{equation}
and \emph{conditional distribution} is
\begin{equation}
  \pi(\rem xi| x_i) \eqdef \pi(\vect x)/\pi(\rem xi).
\end{equation}
  
A Markov chain is a stochastic process $\{\vect X^0, \vect X^1,\vect X^2,\dots\}$ with $X_i$ defined on a common probability space such that
\begin{equation} \label{eq:markovCondition}
  \mathbb P\left( \vect X^{k+1} \in A | \vect X^k= \vect x^k,\dots \vect X^0=\vect x^0\right) 
    = \mathbb P\left( \vect X^{k+1} \in A | \vect X^k= \vect x^k\right) 
\end{equation}
for all events $A$.  
  
%\textcolor{red}{
%  Talk about why we only need to use random variables that have densities, i.e.~are absolutely continuous with respect to Lebesgue measure.
%  But more general notions of Markov chains exist that allow for probability measures that have positive probability for events that have zero Lebesgue measure.
%} 
%
A family of probability densities $K(\vect x,\cdot)$ is a \emph{transition kernel} for the Markov chain if
\begin{equation}
  \int_A K(\vect x^k,\vect x') d\vect x'
    = \mathbb P\left( \vect X^{k+1} \in A | \vect X^k= \vect x^k\right),
\end{equation}
and $K(\cdot , \vect x')$ is measurable (that is, an un-normalized probability density).
For a transition kernel, the corresponding \emph{transition operator} is $\K:L^1\to L^1$ by
\begin{equation}
  \K [\pi](\vect x') = \int K(\vect x,\vect x') \pi(\vect x)d\vect x.
\end{equation}

Now, consider the joint density $\pi(\vect x^N\dots \vect x^0)$ for the truncated chain $\{\vect X^1\dots \vect X^n\}$ with $\pi_0(\vect x)$ the density for $\vect X_0$ and observe 
\begin{align} 
  \pi(\vect x^1) 
    &= \int_{\vect x^0} \pi(\vect x^1,\vect x^0) d\vect x^0 \nonumber\\
    &= \int_{\vect x^0} \pi(\vect x^1|\vect x^0)\pi( \vect x^0) d\vect x^0 \nonumber\\
    &= \int_{\vect x^0} K(\vect x^0,\vect x^1)\pi( \vect x^0) d\vect x^0\nonumber\\
    &= \K [\pi_0](\vect x^1) \\
  \pi(\vect x^2) 
    &= \int_{\vect x^1}\int_{\vect x^0} \pi(\vect x^2,\vect x^1,\vect x^0) d\vect x^0 d\vect x^1\nonumber\\
    &= \int_{\vect x^1}\pi(\vect x^2|\vect x^1)\int_{\vect x^0} \pi(\vect x^1,\vect x^0) d\vect x^0 d\vect x^1\nonumber\\
    &= \int_{\vect x^1}K(\vect x^1,\vect x^2)\int_{\vect x^0} \pi(\vect x^1,\vect x^0) d\vect x^0 d\vect x^1\nonumber\\
    &= \K \circ \K [\pi_0](\vect x^2)\\
    \vdots\nonumber\\
  \pi(\vect x^N)  
    &= \int_{\vect x^{N-1}}\dots\int_{\vect x^0} \pi(\vect x^N, \vect x^{N-1}\dots \vect x^0)d\vect x_0\dots,d\vect x_{N-1}\nonumber\\
    &= \int_{\vect x^{N-1}}\dots\int_{\vect x^0} \pi(\vect x^N| \vect x^{N-1})\pi(\vect x^{N-1}\dots,\vect x^0)d\vect x_0\dots,d\vect x_{N-1} \nonumber\\
    &= \int_{\vect x^{N-1}}K( \vect x^{N-1},\vect x^N)\dots\int_{\vect x^0} K(\vect x^0,\vect x^1)\pi(\vect x^0)d\vect x_0\dots,d\vect x_{N-1} \nonumber\\
    &= \K^N [\pi_0](\vect x^N).
\end{align}
So, the $N$th marginal density of the Markov chain is given by the $N$th composition of the transition operator $\K$ on the initial density $\pi_0$.
In some sense, all of the information of the Markov chain up to $\vect X^N$ is embedded in the transition operator $\K$, since each marginal density and all conditional probabilities are encoded into $K(\vect x, \vect x')$.
Moreover, we see that it is natural to think of a Markov chain evolving as $N$ increases, with the evolution given by successively iterating $\K$.
With this in mind, two natural questions arise -- How does the initial state effect the chain and what is its end behavior? 
These notions are encapsulated by \emph{irreducibly} and \emph{stationarity} respectively.

For a given measure $\lambda$, a Markov chain is $\lambda$-irreducible if for every event $A$ with $\lambda(A) > 0$, there exists an $N$ such that $\int_A \K^N(\vect x,\vect x')dx'$ \citep{robert2013monte}. 
This means that every event that can be measured by $\lambda$ has a positive probability of being reached by the Markov chain in a finite number of steps.

For us, this condition is easily met because we will consider transition kernels that are given by probability density functions with full support over the range of the random variables of interest. 
Hence, the Markov chains relevant to our algorithms are irreducible with respect to Lebesgue measure, and thus irreducible with respect to all measures absolutely continuous with respect to Lebesgue measure, and in particular, those given by probability densities.

A Markov chain with transition operator $\K$ is \emph{stationary} with an \emph{invariant} density $\pi$ if 
\begin{equation} \label{eq:stationarity}
  \K [\pi(\vect x)](\vect x') = \pi(\vect x').
\end{equation}
Note that an invariant distribution $\pi$ is a eigenvector for the transition operator $\K$ corresponding to the eigenvalue $1$.
Moreover, since transition operators consist of probability densities, $\|K\pi_0\|_{L^1} \le \|\pi_0\|_{L^1}$, thus $\pi$ is the eigenvector corresponding to the leading order eigenvalue.
With this viewpoint, there is an interesting connection the power-iteration method for finding leading order eigenvalues and corresponding eigenvectors.
Specifically, when the space of possible outcomes is finite, say $\{\omega_1\dots \omega_n\}$, then all probability densities $\pi_0$ correspond to real $\{\alpha_1\dots\alpha_n\}$ such that $\sum\alpha_i = 1$.
Taking the states $\{\omega_1\dots \omega_n\}$ as basis vectors, the probability densities form a finite dimensional vector space and transition operators correspond to multiplication by a \emph{transition matrix}.
The power-iteration method states that the sequence give by the recursive relation $\pi_k = K\pi_{k-1}/\|K\pi_{k-1}\|$ converges to the leading order eigenvector. 
Hence, the invariant density $\pi = \lim_{k\to \infty}K^n \pi$.
%% I should figure this out sometime
%When the Markov chain is irreducible with respect to the invariant measure $\pi$, then this implies that the  is \emph{unique}. 
%To see this, suppose $\pi'$ is such that $\K\pi' = \pi'$.
%Since $\pi$ is irrecucible, 

There are two last technical conditions, known as Harris recurrence and aperiodicity, that must be defined in order establish the hypotheses of the ergodic theorem for Markov chains.
When the Markov chain is discrete, the \emph{period} of a state $\omega$ is the greatest common denominator of the set $\{m\ge 1; K^m(\omega,\omega > 0\}$; that is, if $\omega$ is $d$-periodic, then returns to state $\omega$ occur multiples of $d$.
For example, the deterministic two state Markov chain associated with the transition matrix
\begin{equation}
  K = \begin{bmatrix}
    0 & 1\\
    1 & 0
  \end{bmatrix}
\end{equation}
has period 2.
A chain is \emph{aperiodic} if each state has period 1. 
Since the period is constant on all states that communicate with $\omega$, an irreducible chain has a unique period for all states.  
Verifying rigorously the requirement of aperiodicity for continuous Markov chains is somewhat more technical, and we cite \citep{liu2008monte} who states that transition kernels associated with Gibbs sampling and Metropolis-Hastings are aperiodic, and the algorithms presented in this work are compositions of such transitions.
See \citep{robert2013monte} for the technical definition and details.

Harris recurrence ensures that a Markov chain re-enters events often enough to ``fill-out'' $\pi$. 
Formally, for a Borel set $A$, the \emph{average number of passages} of $(\vect X^n)$ in $A$ is $\eta_A\eqdef \sum_n I_A(\vect X^n)$ and a Markov chain is \emph{Harris recurrent} if $\mathbb P(\eta_A = \infty|X_0=x) =1$ \citep{robert2013monte}. 
Again, verifying this condition is beyond the scope of this work, and we cite \citep{robert2013monte} who ensures that transitions associated with Gibbs sampling and Metropolis-Hastings are Harris recurrent.

We now state the main theorem that allows for the end behaviour Markov chains to be used as tools for estimating statistics of a given probability distribution:
\begin{thm}
  \citep{tierney1994markov} Suppose $\K$ defines a stationary Markov chain with invariant density $\pi$. If the chain is $\pi$-irreducible and Harris recurrent, then $\pi$ is unique and for any initial density $\pi_0$ and all $\vect x$ but a subset whose measure under $\pi$ is zero,
  \begin{enumerate}[(i)]
    \item Almost surely with respect to $\pi$, for any integrable $h$ \begin{equation} \lim_{N\to \infty}\frac 1N\sum_{n=1}^N h(\vect X^n) = \int h(\vect x) \pi(\vect x) d\vect x. \label{eq:ergodicStat}\end{equation}
    \item If in addition, the chain is aperiodic, then \begin{equation} \lim_{N\to \infty}\|\K^N\pi_0 - \pi\|_{TV} = 0. \label{eq:ergodicDist}\end{equation}
  \end{enumerate}
\end{thm}
\Cref{eq:ergodicStat} of the ergodic theorem allows us to use chain averages to estimate statistics about $\pi$.  
\Cref{eq:ergodicDist} justifies using the `late stages' of the chain as approximate samples of $\pi$.

The goal of MCMC methods are to simulate a Markov chain \emph{designed} so that it has a desired density $\pi$.  
In the context of our Bayesian hierarchical model, this will be the posterior density $\pi(\vect x, \lambda, \delta| \vect b)$.
A widely used method that can be used when sampling from full conditional distributions is available, known as \emph{Gibbs sampling}, is presented in the following section.

\subsection{Gibbs sampling}

The origin of the Gibbs sampler is relatively recent (despite its eponymous relation to the 19th century physicist Josiah Gibbs) and has its origins in computational imaging. 
In \citep{geman1984stochastic}, they modeled the spatial structure of pixels in an image via the Gibbs distribution which originally arose from modelling particles in a lattice system.
They developed the following simulation algorithm for approximating the mode of the posterior of the Gibbs distribution.
Because of its ease of implementation and ubiquitous application, the Gibbs sampler has become the workhorse of the MCMC world \citep{robert2013monte}, and, arguably, its fame has overtaken that of its namesake.
When the Gibbs sampler is applied to hierarchical Bayesian posteriors, it is sometimes referred to as the hierarchical Gibbs sampler, as is the case in this work for analyzing the posterior density $\pi(\vect p,\delta,\lambda|\vect b)$.


The following algorithm outlines Gibbs sampling for simulating the transition of a general $p$-component Markov chain:
\begin{algorithm}
\caption{Gibbs sampler} \label{alg:gibbs}
  Given $\vect x^{k-1} = (x_1^{k-1}\dots x_p^{k-1})$, simulate
\begin{algorithmic}[0]
  \STATE 1. $X_1^{k} \sim \pi(x_1|x_2^{k-1},x_3^{k-1}\dots x_p^{k-1})$
  \STATE 2. $X_2^{k} \sim \pi(x_2|x_1^k,x_3^{k-1}\dots x_p^{k-1})$ 
  \STATE \dots
  \STATE p. $X_p^{k} \sim \pi(x_p|x_1^k,x_2^{k}\dots x_{p-1}^{k})$
\end{algorithmic}
\end{algorithm}

\Cref{alg:gibbs} simulates the outcomes from the transition kernel 
\begin{equation}
  K(\vect x,\vect x') = \pi(x_p'|\rem x{p}')\dots\pi(x_2'|x_1',\rem x{12})\pi(x_1'|\rem x1).
\end{equation}
Note that we can view the action of the transition in steps since it is factors, i.e.
\begin{align}
  \K [\pi_0](\vect x') 
    &= \int K(\vect x,\vect x') \pi_0(\vect x) d\vect x \nonumber \\
    &= \int_{x_p}\dots\int_{x_1} \pi(x_p'|\rem x{p}')\dots\pi(x_2'|x_1',\rem x{12})\pi(x_1'|\rem x1)dx_1\dots dx_p \nonumber\\ 
    &= \int_{x_p}\pi(x_p'|\rem xp')\int_{x_{p-1}} \pi(x_{p-1}'|\rem x{p,p-1}'x_p)\dots\int_{x_1} \pi(x_1'|\rem x1) \pi_0(x_1\dots x_p)dx_1\dots dx_p. \label{eq:iteratedGibbsKernel}
\end{align}
Each integration in \eqref{eq:iteratedGibbsKernel} can be thought of as a sub-transition on components of $\pi_0(x_1\dots x_p)$; that is, let
\begin{equation}
  \K_i[\pi_0(\vect x)](\vect x') \eqdef \int_{x_i} \pi(x_i'|x_1',\dots x_{i-1}',x_{i+1}\dots x_p) \pi_0(\vect x)dx_i,
\end{equation}
then we can express $\K = \K_p\circ\K_{p-1}\circ \dots \circ\K_1$.
We note that functionally each operator $\K_i$ depends on $(x_1\dots x_{i-1},x_{i+1}\dots x_p)$ being given, and that successively integrating removes dependence. 
For example $\K_1$ depends on $(x_2\dots x_p)$, $\K_2\circ K_1$ depends on $(x_3\dots x_p$), etc.~until the full composition $\K$ does not depend on $\vect x$.

In this form, it will be easy to see that the Gibbs sampler is invariant with respect to $\pi$, and the technique used in the proof (analyzing the transition kernel as a composition of conditional operators) will be useful for designing and verifying the stationarity of the proceeding algorithms.
\begin{prop} The transition kernel associated to \Cref{alg:gibbs} produces a Markov chain that is invariant to the density $\pi$.
\end{prop}
\begin{proof}
  Observe that
  \begin{align}
    \K_1[\pi(\vect x)](\vect x') 
      &=\int_{x_1} \pi(x_1'|x_2,\dots x_p) \pi(x_1\dots x_p)dx_1\nonumber\\
      &=\int_{x_1} \frac{\pi(x_1',x_2,\dots x_p) \pi(x_1\dots x_p)}{\pi(x_1',x_2\dots x_p)}dx_1\nonumber\\
      &=\pi(x_i',x_2,\dots x_p).
  \end{align}
  Moreover, given $\K_{i-1} \circ\dots \circ \K_1 = \pi(x_1'\dots x_{i-1}',x_i\dots x_p)$, then
  \begin{align}
    \K_i \circ\dots \circ \K_1[\pi(\vect x)](\vect x') 
      &=\int_{x_i} \pi(x_i'|x_1',\dots x_{i-1}',x_{i+1}\dots x_p) \pi(x_1'\dots x_{i-1}',x_i\dots x_p)dx_i\nonumber\\
      &=\int_{x_i} \frac{\pi(x_1',\dots x_{i}'\dots x_p) \pi(x_1'\dots x_{i-1}',x_i\dots x_p)}{\pi(x_1',\dots x_{i-1}',x_{i+1}\dots x_p)}dx_i\nonumber\\
      &=\pi(x_1',x_2' \dots x_i'\dots x_p).\label{eq:partialCompositionGibbs}
  \end{align}
  By induction, $\K [\pi(\vect x)](\vect x') = \K_p\circ\dots\circ \K_1 [\pi(\vect x)](\vect x') = \pi(x_1',x_2'\dots x_p')$.
  Hence $\pi$ is invariant.
\end{proof}
Note that the partial composition $\K_i\circ\dots\circ\K_1$ is invariant with respect to $\pi(x_1\dots x_i|x_{i+1},\dots,x_p)$ when $(x_{i+1}\dots x_p)$ are given, then $\pi(\vect x)/\pi(x_{i+1}\dots x_p)= \pi(x_1\dots x_{i}|x_{i+1}\dots x_p)$ and since each integration does not depend on $(x_{i+1}\dots x_p)$ by \eqref{eq:partialCompositionGibbs}
\begin{align}
  \K_i\circ\dots\circ \K_1 [\pi(x_1\dots x_i|x_{i+1}\dots x_p)](\vect x') 
  &= \frac{\pi(x_1'\dots x_p')}{\pi(x_{i+1}\dots x_p)} = \pi(x_1'\dots x_i'|x_{i+1}\dots x_p).
\end{align}

Viewing Gibbs sampling as composed conditional sub-transitions allows for the flexibility to design and analyze algorithms that modify each sub-transition step. 
Proving that the modifications retain the invariant distribution of the chain can focus on the sub-transition operator associated with the modified step and fit generally into the simple argument presented above. 

As will be seen in following sections, the Gibbs sampler will produce good Monte Carlo estimates for the discretized PSF $\vect p$ and the noise level given by $\lambda$. 
However, the $\delta$ component of the chain exhibits poor convergence, hence, the asymptotic application of the ergodic theorem for Markov chains for the joint variable $(\vect p,\lambda,\delta)$ is not available.
In fact, \citep{agapiou2014analysis} gave theory that showed that the infinite dimensional hierarchical Gibbs sampler for linear inverse problems with $\lambda$ known and Laplacian regularization will always exhibit degenerate convergence in $\delta$ when the discrete representation of the unknown approaches the infinite dimensional representation.
They presented an algorithm that ``marginalizes'' the dependence of the unknown with $\delta$.
This ``marginalization'' process can be carried out in general and is known as partial collapse, and is presented in \citep{van2008partially}.
In their paper, they showed various examples of partially collapsing the Gibbs sampler and how it can lead to Markov chains that no longer have $\pi$ as an invariant density.
They also presented theory that this process in general improves chain convergence, however they did not give an explicit argument that shows that partial collapse maintains the invariant density $\pi$.
We outline this process for the Gibbs sampler presented above, and show explicitly that it maintains $\pi$ as an invariant density in the next section.

\subsection{The partially collapsed Gibbs sampler}
The partially collapsed Gibbs (PCG) sampler we present in this section is based on the work of \citep{van2008partially,van2015metropolis}, where they outlined how the algorithm arises naturally from trying to improve the convergence of the standard Gibbs sampler.
However, in both \citep{van2008partially,van2015metropolis}, they highlight that application of partial collapse must be done with care, else the resulting Markov chain may no longer be invariant with respect to $\pi$, and thus statistics derived from the chain will not converge to those of the distribution of interest.
They even give some examples in the literature where partial collapse was implemented improperly, and resulted in incorrectly estimated parameters of interest.
They carefully outlined methods for ensuring that the pitfalls of improper sampling are avoided, although did not formally prove the invariance of the resulting Markov chains.
In this section, we give rigorous arguments that show the Markov chains associated with proper partial collapse are indeed invariant.

Consider the following modification of step p-1.~in \Cref{alg:gibbs}:
\begin{algorithm}[h]
\caption{$p$-Conditioned Gibbs sampler} \label{alg:conditionedGibbs}
Given $\tilde{\vect x}^{k-1} = (x_1^{k-1}\dots \tilde x_p^{k-1},x_p^{k-1})$, simulate 
\begin{flalign*}
  \text{1.~}&   X_1^{k} \sim \pi(x_1|x_2^{k-1},x_3^{k-1}\dots x_p^{k-1})                    & \\
  \text{2.~}&   X_2^{k} \sim \pi(x_2|x_1^k,x_3^{k-1}\dots x_p^{k-1})                        & \\
  \vdots &                                                                                  & \\
  \text{p-1.~}& (X^k_{p-1},\tilde X^k_{p}) \sim \pi (x_{p-1},x_p|x_1^k,x_2^k\dots x_{p-2}^k)& \\
  \text{p.~}&   X_p^{k} \sim \pi(x_p|x_1^k,x_2^{k}\dots x_{p-1}^{k})                        & 
\end{flalign*}
%\begin{algorithmic}[0]
%  \STATE \mbox{\hspace{9pt}1.} $X_1^{k} \sim \pi(x_1|x_2^{k-1},x_3^{k-1}\dots x_p^{k-1})$
%  \STATE \mbox{\hspace{9pt}2.} $X_2^{k} \sim \pi(x_2|x_1^k,x_3^{k-1}\dots x_p^{k-1})$ 
%  \STATE \dots
%  \STATE p-1. $(X^k_{p-1},\tilde X^k_{p}) \sim \pi (x_{p-1},x_p|x_1^k,x_2^k\dots x_{p-2}^k)$
%  \STATE \mbox{\hspace{9pt}p.} $X_p^{k} \sim \pi(x_p|x_1^k,x_2^{k}\dots x_{p-1}^{k})$
%\end{algorithmic}
\end{algorithm} 

If $\tilde{\vect X}^k = (X_1^k\dots X_{p-1}^k,\tilde X_{p}^k,X_p^k)$, then the corresponding transition operator is
\begin{equation}
  \K\pi_0 = \K_p\circ \tilde \K_{p-1}\dots \K_2\circ \K_1 \pi_0
\end{equation}
where the $\tilde\K_{p-1}$ is integration with respect to $(x_{p-1},\tilde x_p)$ against the transition kernel
\begin{equation}
  \tilde K_{p-1}(\tilde{\vect x},\tilde{\vect x}') \eqdef \tilde K_{p-1}(\tilde{\vect x}') = \pi(x_{p-1}',\tilde x_p'|x_1',x_2'\dots x_{p-2}')
\end{equation}
%\begin{equation}
%  \tilde \K_{p-1}[\pi(\tilde{\vect x})](\tilde{ \vect x}') = 
%\end{equation}
\Cref{alg:conditionedGibbs} produces a Markov chain with $p+1$ components by drawing $(X_{p-1}^k,\tilde X_p^k)$ jointly at step p-1, and note that the transition to the next state does not depend on previous values of $\tilde X_p$.
This lack of dependence is crucial for partially collapsing components out of the sampler, else the resulting transition kernel will \emph{not} produce a Markov chain invariant with respect to $\pi$.
\begin{prop}\label{thm:conditionedGibbsStationary}
  The Markov chain associated with the transition kernel corresponding to \Cref{alg:conditionedGibbs} is invariant with respect to $\pi(\vect x)\pi(\tilde{x_p}|\vect x)$.
\end{prop}
\begin{proof}
  Denote the transition operator associated to \Cref{alg:conditionedGibbs} as $\K$, then
  \begin{align}
    \tilde\K\Big[ \pi(\vect x)&\pi(\tilde x_p|\vect x)\Big](\tilde{\vect x}') \nonumber \\ 
    &= \K_p \tilde\K_{p-1} \K_{p-2}\circ\dots\circ\K_{1} \big[\pi(\vect x)\pi(\tilde x_p|\vect x)\big](\tilde{\vect x}') \nonumber\\
    &= \int\limits_{x_p} \pi(x_p'|\rem xp')\iint\limits_{\tilde x_p,x_{p-1}}\tilde K_{p-1}(\tilde{\vect x}')\idotsint\limits_{x_{p-2}\dots x_1}\dots \pi(\vect x)\pi(\tilde x_p|\vect x)dx_1\dots d\tilde x_p dx_p \nonumber\\
    &=\int\limits_{x_p}\pi(x_p'|\rem xp') \int\limits_{x_{p-1}}\tilde K_{p-1}(\tilde{\vect x}')\int\limits_{x_{p-2}}\dots \int\limits_{x_1}\pi(x_1'|\rem x1)\pi(\vect x)\left(\int_{\tilde x_p}\pi(\tilde x_p|\vect x)\tilde x_p \right)d\vect x \label{eq:conditionedGibbsCalc}
  \end{align}
  where we used Fubini's theorem to integrate first in $\tilde x_p$ for which each kernel $K_i$ does not depend, and $\int\pi(\tilde x_p|\vect x)d\tilde x_p = 1$. 
  Now, each of the inner $p-2$ integrations express the action of the first $p-2$ steps of the standard Gibbs sampler, so continuing from \eqref{eq:conditionedGibbsCalc}, 
  \begin{align}
    \tilde\K\Big[ \pi(\vect x)\pi(\tilde x_p|\vect x)\Big](\tilde{\vect x}')
      &= \int_{x_p}\pi(x_p'|\rem xp') \int\limits_{x_{p-1}}\tilde K_{p-1}(\tilde{\vect x}')\,\cdot\,\K_{p-2}\circ\dots\circ \K_{1}[\pi(\vect x)](\vect x')\nonumber \\ 
      &= \int_{x_p}\pi(x_p'|\rem xp') \int\limits_{x_{p-1}}\pi(x_{p-1}',\tilde x_p'|x_1',x_2'\dots x_{p-2}')\cdot\pi(x_1'\dots x_{p-2}', x_{p-1},x_p)\nonumber \\ 
      &= \pi(x_p'|\rem xp') \pi(x_{p-1}',\tilde x_p'|x_1',x_2'\dots x_{p-2}')\cdot\pi(x_1'\dots x_{p-2}')\nonumber \\ 
      &= \frac{\pi(\vect x')\pi(x_1',x_2'\dots x_{p-1}', \tilde x_p')}{\pi(\rem xp')}\nonumber \\ 
      &= \pi(\vect x')\pi(\tilde x_p'|\rem xp').
  \end{align}
%%%%%%%%%%%%%%%%%
% Uncomment to show that q is different when conditioning happens at a different p
%\begin{thm}\label{thm:conditionedGibbsStationary}
%  The Markov chain associated with the transition kernel corresponding to \Cref{alg:conditionedGibbs} is invariant with respect to $\pi(\vect x)q(\tilde{\vect x})$ with $\int q(\tilde{\vect x})\,d\tilde x_p$.
%\end{thm}
%\begin{proof}
%  Let 
%  \begin{equation} \label{eq:auxGibbsVariable}
%    q(x_1\dots x_{p-1},\tilde x_p,x_p) = 
%      \pi(x_1,x_2,\dots x_3|x_{p-1},\tilde x_p) 
%      \pi(x_{p-1}|x_1\dots x_{p-2},x_p)
%      \pi(x_p),
%  \end{equation} \label{eq:auxGibbsVariableInt}
%  and observe that
%  \begin{equation}
%  \begin{split}
%    \int_{\tilde{\vect x}} q(\tilde{\vect x})d\tilde{\vect x} 
%      &=
%  \end{split}
%  \end{equation}
%  Arguing as in the proof for stationarity of the Gibbs sampler, we have
%  \begin{equation}
%    \begin{split}
%    \big[\K_{p-2}\circ\dots\circ\K_{1} \pi(\tilde{\vect x})q(\tilde{\vect x})\big](\tilde{\vect x}') 
%     &= \pi(x_1',x_2'\dots x_{p-2}',x_{p-1},\tilde x_p,x_p).
%    \end{split}
%  \end{equation}
%  Applying $\tilde K_{p-1}$, we have
\end{proof}
Note that it is essential that each sub-kernel $K_i$ does not depend on $\tilde x_p$,  else the initial integration in $\tilde x_p$ would involve products of kernels depending on $\tilde x_p$ with $\pi(\tilde x_p|\rem xp)$. %, and the sampler may no longer be invariant with respect to $\pi$.
Also, the placement

In some sense, this algorithm is artificial, as we do not need to sample the auxiliary variable $\tilde X_p$.
Moreover, if we integrate the invariance condition
\begin{equation} \label{eq:pcGibbsInvariance}
  \int_{\tilde x_p'}\tilde\K [\pi(\vect x)\pi(\tilde x_p|\rem xp)](\tilde{\vect x})d\tilde x_p' = \pi(\vect x')\int_{\tilde x_p'}\pi(x_p'|\rem xp')dx_p' = \pi(\vect x'),
\end{equation}
This results in the same transition kernel as the $p$-Conditioned sampler except for at step $p-1$
\begin{equation}
  \bar K_{p-1}(\tilde{\vect x},\tilde{\vect x}') \eqdef \int_{x_p'}\pi(x_{p-1}',\tilde x_p'|x_1',x_2'\dots x_{p-2}') = \pi(x_{p-1}'|x_1',x_2'\dots x_{p-2}').
\end{equation}
By \eqref{eq:pcGibbsInvariance}, the corresponding Markov Chain is invariant with respect to $\pi$.
The following algorithm simulates this chain:
\begin{algorithm}[h]
\caption{$p$-Partially Collapsed Gibbs sampler} \label{alg:conditionedGibbs}
Given $\tilde{\vect x}^{k-1} = (x_1^{k-1}\dots \tilde x_p^{k-1},x_p^{k-1})$, simulate 
\begin{flalign*}
  \text{1.~}&   X_1^{k} \sim \pi(x_1|x_2^{k-1},x_3^{k-1}\dots x_p^{k-1})                    & \\
  \text{2.~}&   X_2^{k} \sim \pi(x_2|x_1^k,x_3^{k-1}\dots x_p^{k-1})                        & \\
  \vdots &                                                                                  & \\
  \text{p-1.~}& X^k_{p-1} \sim \pi (x_{p-1}|x_1^k,x_2^k\dots x_{p-2}^k)                     & \\
  \text{p.~}&   X_p^{k} \sim \pi(x_p|x_1^k,x_2^{k}\dots x_{p-1}^{k})                        & 
\end{flalign*}
\end{algorithm} 

There is one last modification to the transition kernel that will be required.
In many cases, as will be the case of PSF reconstruction, a simulation from $\pi(x_{p-1}|x_1\dots x_{p-2})$ may not be directly available.
In the standard Gibbs case, when a full conditional density is difficult to simulate, a compromise suggested first by \citep{muller1992alternatives} and outlined in \citep{robert2013monte} is the so-called ``Metropolis-within-Gibbs'' method.
The idea is to replace a direct sample of the conditional density with a Metropolis-Hastings transition. 
In the next section we review Metropolis-Hastings, and show that directly substituting a Metropolis-Hastings transition into the $p$-partially collapsed Gibbs sampler remains stationary.

\subsection{Metropolis-Hastings within partially collapsed Gibbs}
The Metropolis-Hastings algorithm \citep{metropolis1953equation} has been studied extensively as an MCMC method, and over the last half-century, has been generalized and adapted to encompass a large class of MCMC algorithms for simulating samples for a large class of problems. 
In fact, Gibbs sampling can be viewed as successive Metropolis-Hastings transitions \citep{robert2013monte}.

We will focus on random walk Metropolis-Hastings and how it can be incorporated into the partially collapsed Gibbs sampler.
Again, see one of the books \citep{robert2013monte,liu2008monte} and references there for a complete treatment.

Consider the following algorithm for simulating a transition
\subsection{Partially collapsed Gibbs sampling for PSF estimation}
The effect of this process is that we have removed conditioning of $X_p^{k-1} = x_p^{k-1}$ from the sample $X^k_{p-1}$. 
Note that steps of the algorithm can be cyclicly permuted with the appropriate re-labeling with respect to $k$ without chaning the full transition kernel (each sub-transition \emph{will} change).
The merely changes the initial distribution of the chain.

We can generalize this process by removing the conditioning on either $X_{p-1}$ or $X_p$ on $X_{p-2}$.
Without loss of generality, $X_{p-2}$ can be choosen from $X_1\dots X_{p-2}$ by relabeling.
By noting that $K_p$ and $K_{p-1}$ do not depend on $\vect x$, a similar re-ordering of integration with the auxilary variable as in \eqref{eq:conditionedGibbsCalc} will be valid.
Hence, $X_p$ can be partially collapsed out of any number of proceeding variables.

In practice, one starts with the standard Gibbs sampler, and observes convergence of each component.
If a component exhibits poor convergence (see \Cref{sec:evaluatingConvergence}), see if any conditioned variables can be partially collapsed.
If it is possible to sample the density with one of the conditoined variable collapsed out, re-order the sampler so that the collapsed variable is last and each of the poorly converging variable directly proceeds it. 
The theory presented in \citep{van2008partially} gaurantees that the convergence of $(\vect X^k)$ will be improved.
If some components still exhibit poor convergence, continue be removing the conditioning of one of the previous $p-1$ variables.
See \citep{van2008partially} for examples and a further discussion of the general process of partially collapsing variables.


%So far, we have only shown that partial collapse is available in the last two steps of the sampler.
%If two or more components require partial collapse, then we will need one more modification technique which involves permuting steps.
%In the case of the standard Gibbs sampler, simply by relabeling, it is clear that any permutation of the sub-transition steps is allowed.
%However, as was indicated in the proof of invariance, it was crucial that each sub-transition kernel did not depend on the auxiliary variable.
%Yet, the ergodic theorem will allow for freedome to permute \emph{cyclically}.
%
%\begin{lem}
%  Suppose $\K_p\circ\dots\circ\K_1 = \K$ is a transition kernel for an aperiodic $\pi$-invariant and $\pi$-irreducible Markov chain. Then, any cyclic permutation of the sub-transitions, $\K' = \K_{l-1}\circ \dots \K_1\circ\K_p\circ\dots\circ\K_{l+1}\circ\K_l$, is also invariant with respect to $\pi$.
%\end{lem}
%\begin{proof}
%\textcolor{red}{
%  Outline:  By \citep[Theorem 6.38]{robert2013monte}, the Markov chain associated with $\K'$ has a unique (up to a multiplicative factor) invariant density $\pi'$.
%  Then, the ergodic theorem says that it is unique.
%  Then, associativity says
%  \begin{equation}
%    \|(\K_{l-1}\circ \dots \K_1\circ\K_p\circ\dots\circ\K_{l-1}\circ\K_l)^n\K_{l-1}\dots\K_1\pi - \tilde \pi\|_{TV}
%  \end{equation}
%}
%
%\end{proof}

\section{Evaluating Convergence} \label{sec:evaluatingConvergence}
\textcolor{red}{
  This section is to introduce all of the chain statistics we will use to see how our algorithm is better than Gibbs.
  We also compare substeps in the Metropolis step.
}
  \subsection{Estimating Burn-in}
  \textcolor{red}{
  Re-read PC Gibbs on John's section and basically copy his ideas.
  Talk about how to interpret the ergodic theorem.
  }
  \subsection{Integrated Autocorrelation}
  \textcolor{red}{
  Talk about IAC and how one can then develop effective sample size.  
  Pretty straight forward, again re-reading PC Gibbs.  
}

\section{Sampling the PSF posterior}
  \subsection{Gibbs sampling the PSF posterior}
  \subsection{Partially collapsed Gibbs sampling for PSF reconstruction}
  \subsection{Blocking the sampler and a connection to Marginal then conditional sampling}
\end{chapter}
